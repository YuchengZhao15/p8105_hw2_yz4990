---
title: "p8105_hw2_yz4990"
author: "Yucheng Zhao"
date: "2024-10-01"
output: md_document
---


```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

initial data cleaning, change col types, retain useful variables, convert from char to logical
```{r}
transit_df = read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")
) |> 
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), 
         entry, vending, entrance_type, ada) |> 
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE)
  )

```
The dataset after cleaning include `r ncol(transit_df)` variables, including line, station name, station latitude, station longitude, routes from 1 to 11, entry, vending, entrance type, and ada compliance. I started the data cleaning process with importing the data, specifying columns Route 8 to 11 being character, and standardizing the name of columns. Then, I retained the variables needed later and convert the entry variable from character "YES" and "NO" to logical variable "TRUE" and "FALSE." The dimension of the resulting data is `r nrow(transit_df)`rows x `r ncol(transit_df)` columns. The dataset is not tidy because route number and route should be 2 variables instead of having route1, route2, ... route11 as the variables. 


distinct stations
```{r}
distinct_stations = transit_df |> 
  select(station_name, line) |> 
  distinct()
```
There are `r nrow(distinct_stations)` distinct stations. 

find ADA compliant stations
```{r}
ada_stations = transit_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
There are `r nrow(ada_stations)` that are ADA compliant.


proportion of station entrances / exits without vending allow entrance
```{r}
prop_without_vending = transit_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
  
```
The proportion of station entrances / exits without vending allow entrance is `r prop_without_vending`.


tidy the dataset, find distinct stations that serve the A train and those are ADA compliant among them
```{r}
dist_a_train = transit_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route"
    ) |> 
  filter(route == "A") |> 
  select(station_name, line) |> 
  distinct()


dist_ada = transit_df |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route"
    ) |> 
  filter(route == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
There are `r nrow(dist_a_train)` distinct stations that serve the A train and `r nrow(dist_ada)` distinct stations that are ada compliant among them.



## Problem 2

read and clean the dataset from "Mr. Trash Wheel", change sports_balls to integer
```{r}
mr_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                   sheet = "Mr. Trash Wheel", 
                   range = "A2:N653", 
                   na = c("", "NA")) |> 
  janitor::clean_names() |> 
  mutate(
    sports_balls = as.integer(round(sports_balls, 0))
  ) |> 
  mutate(
    trash_wheel_name = "mr",
    year = as.numeric(year),
    month = tolower(month)
  )
```

read and clean the datasets from "Professor Trash Wheel" and "Gwynnda Trash Wheel"
```{r}
prof_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                   sheet = "Professor Trash Wheel", 
                   range = "A2:M121", 
                   na = c("", "NA")) |> 
  janitor::clean_names() |> 
  mutate(
    trash_wheel_name = "professor",
    month = tolower(month)
  )

gw_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
                   sheet = "Gwynnda Trash Wheel", 
                   range = "A2:L265", 
                   na = c("", "NA")) |> 
  janitor::clean_names() |> 
  mutate(
    trash_wheel_name = "gwynnda",
    month = tolower(month)
  )
```

combine the 3 datasets with the new variable "trash_wheel_name" 
```{r}
trash_wheel = 
  bind_rows(mr_df, prof_df, gw_df)

```

calculate the total weight and number of cigarette butts
```{r}
total_weight_prof = filter(trash_wheel, trash_wheel_name == "professor") |> 
  pull(weight_tons) |> 
  sum(na.rm = TRUE)

june22_cig_gw = filter(trash_wheel, trash_wheel_name == "gwynnda", year == 2022, month == "june") |> 
  pull(cigarette_butts) |> 
  sum(na.rm = TRUE)
```
The 3 dataset from "Mr. Trash Wheel," "Professor Trash Wheel," "Gwynnda Trash Wheel" each has `r nrow(mr_df)`, `r nrow(prof_df)`, and `r nrow(gw_df)` observations respectively. The combined dataset "trash_wheel" has `r nrow(trash_wheel)` observations. Its key variables include the date ("date"), weight of trash in tons ("weight_tons"), volume of trash in cubic yards ("volume_cubic_yards"), and the type of trash (including "plastic_bottles," "cigarette_butts," "glass_bottles," etc). The total weight of trash collected by Professor Trash Wheel is `r total_weight_prof` tons and the total number of cigarette butts collected by Gwynnda in June of 2022 is `r june22_cig_gw`. 


## Problem 3

read and clean the 3 datasets
```{r}
bakers_df = read_csv("./gbb_datasets/bakers.csv",
                     na = c("", "NA", "N/A") ) |> 
  janitor::clean_names() |> 
  rename(
    baker = baker_name
  )

bakes_df = read_csv("./gbb_datasets/bakes.csv",
                    na = c("", "NA", "N/A")) |> 
  janitor::clean_names()

results_df = read_csv("./gbb_datasets/results.csv",
                      na = c("", "NA", "N/A"), 
                      skip = 2) |> 
  janitor::clean_names()
```

using anti_join() to check for completeness and correctness
```{r}
anti_join(bakes_df, bakers_df, by = c("baker", "series"))
anti_join(results_df, bakers_df, by = c("baker", "series"))
anti_join(results_df, bakes_df, by = c("baker", "episode", "series"))
```

keep only the first name of bakers in bakers_df, combine and organize the datasets, export the final dataset
```{r}
bakers_df = mutate(bakers_df, 
                   baker = word(baker, 1))

gbbo_df = full_join(bakes_df, bakers_df, by = c("baker", "series")) |> 
  full_join(results_df, by = c("baker", "episode", "series")) |> 
  select(series, episode, baker, baker_age, baker_occupation, signature_bake, technical, hometown, show_stopper, result)

write_csv(gbbo_df, "./gbb_datasets/gbbo_df")
```
I started with reading and cleaning each of the 3 datasets. I used janitor::clean_names() function to standardize the variable names and glanced over each datasets checking for the same or different variables they have and the missing values. I found it's challenging that although all 3 datasets contained the names of the bakers ("baker" and "baker_name"), bakers_df used the full names of bakers while the other 2 datasets used only the first names. Since some bakers have the same first name, this creates problem for combining the datasets. I decided to handle this by removing the last name of bakers in bakers_df and use the remaining first name for merging the datasets. 

I chose to use full_join() function to merge the datasets instead of left_join() or right_join() to include all the variables in the final dataset, ensuring no useful information is lost. I first merged bakes_df and bakers_df by the "baker" and "series" columns and then merged the new dataset with results_df by "backer," "episode," and "series." Since some bakers share the same first name, I included "series" and "episode" to ensure the columns were matched correctly. 

Then, I rearranged the columns in the final dataset gbbo_df to make it easier to read and more organized. It contains `r ncol(gbbo_df)` varaibles and `r nrow(gbbo_df)` observations in total. Lastly, I saved the dataset into a csv filt in the directory using write_csv() function. 






create a reader-friendly table using knitr
```{r}

winner_df <- gbbo_df %>%
  filter(series %in% 5:10, result %in% c("WINNER", "STAR BAKER")) |> 
  select(series, episode, baker, result)

knitr::kable(winner_df)
```
The predicable overall winner would be Richard, as he has the maximum number of being "WINNER" or "STAR BAKER." The surprisees would be the bakers who have the least number of being "WINNER" or "STAR BAKER," such as Benjamina, Chetna, and Dan. 

```{r}

viewers_df <- read_csv("./gbb_datasets/viewers.csv", na = c("", "NA", "N/A")) |> 
  janitor::clean_names()

head(viewers_df, 10)

```
calculate averages of viewership for series 1 and 5
```{r}
avg_1 = mean(pull(viewers_df, series_1), na.rm = TRUE)
avg_5 = mean(pull(viewers_df, series_5), na.rm = TRUE)


```
The average viewership for series 1 and 5 are `r avg_1` and `r avg_5`


